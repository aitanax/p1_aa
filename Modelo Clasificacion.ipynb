{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TRANSFORMACIÓN A MODELO DE CLASIFICACIÓN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRUPO DE PRÁCTICAS: 82\n",
    "- AITANA ANTONIA ORTIZ GUIÑO    100472097\n",
    "- MARÍA PARRA MUÑOZ             100472195\n",
    "ENLACE AL REPOSITORIO: https://github.com/aitanax/practica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as df\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, mean_squared_error, mean_absolute_error, r2_score, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_ava = pd.read_csv('wind_ava.csv.gz', compression=\"gzip\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>energy</th>\n",
       "      <th>p54.162.13</th>\n",
       "      <th>p55.162.13</th>\n",
       "      <th>cape.13</th>\n",
       "      <th>p59.162.13</th>\n",
       "      <th>lai_lv.13</th>\n",
       "      <th>lai_hv.13</th>\n",
       "      <th>u10n.13</th>\n",
       "      <th>v10n.13</th>\n",
       "      <th>...</th>\n",
       "      <th>t2m.13</th>\n",
       "      <th>stl2.13</th>\n",
       "      <th>stl3.13</th>\n",
       "      <th>iews.13</th>\n",
       "      <th>inss.13</th>\n",
       "      <th>stl4.13</th>\n",
       "      <th>fsr.13</th>\n",
       "      <th>flsr.13</th>\n",
       "      <th>u100.13</th>\n",
       "      <th>v100.13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-02 18:00:00</td>\n",
       "      <td>402.71</td>\n",
       "      <td>2.510824e+06</td>\n",
       "      <td>9.186295</td>\n",
       "      <td>13.527577</td>\n",
       "      <td>1.386937e+06</td>\n",
       "      <td>2.344111</td>\n",
       "      <td>2.432983</td>\n",
       "      <td>-0.757587</td>\n",
       "      <td>-1.922799</td>\n",
       "      <td>...</td>\n",
       "      <td>280.473098</td>\n",
       "      <td>281.042026</td>\n",
       "      <td>281.462478</td>\n",
       "      <td>-0.057958</td>\n",
       "      <td>-0.138650</td>\n",
       "      <td>284.684755</td>\n",
       "      <td>0.404731</td>\n",
       "      <td>-5.927092</td>\n",
       "      <td>-1.780562</td>\n",
       "      <td>-4.443617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-03 00:00:00</td>\n",
       "      <td>696.80</td>\n",
       "      <td>2.513173e+06</td>\n",
       "      <td>8.849569</td>\n",
       "      <td>6.896412</td>\n",
       "      <td>1.153526e+06</td>\n",
       "      <td>2.343719</td>\n",
       "      <td>2.432838</td>\n",
       "      <td>-1.412620</td>\n",
       "      <td>-1.403011</td>\n",
       "      <td>...</td>\n",
       "      <td>278.286616</td>\n",
       "      <td>280.747406</td>\n",
       "      <td>281.486541</td>\n",
       "      <td>-0.103576</td>\n",
       "      <td>-0.083050</td>\n",
       "      <td>284.667948</td>\n",
       "      <td>0.404920</td>\n",
       "      <td>-5.913881</td>\n",
       "      <td>-3.743344</td>\n",
       "      <td>-3.129469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-03 06:00:00</td>\n",
       "      <td>1591.15</td>\n",
       "      <td>2.509627e+06</td>\n",
       "      <td>7.924080</td>\n",
       "      <td>4.774439</td>\n",
       "      <td>1.098754e+06</td>\n",
       "      <td>2.343300</td>\n",
       "      <td>2.432704</td>\n",
       "      <td>-2.290185</td>\n",
       "      <td>-0.754580</td>\n",
       "      <td>...</td>\n",
       "      <td>277.206490</td>\n",
       "      <td>280.114863</td>\n",
       "      <td>281.487095</td>\n",
       "      <td>-0.165721</td>\n",
       "      <td>-0.036241</td>\n",
       "      <td>284.651914</td>\n",
       "      <td>0.405704</td>\n",
       "      <td>-5.908272</td>\n",
       "      <td>-5.097203</td>\n",
       "      <td>-1.157748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-03 12:00:00</td>\n",
       "      <td>1338.62</td>\n",
       "      <td>2.510571e+06</td>\n",
       "      <td>6.922709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.076021e+06</td>\n",
       "      <td>2.342830</td>\n",
       "      <td>2.432514</td>\n",
       "      <td>-3.497855</td>\n",
       "      <td>1.271028</td>\n",
       "      <td>...</td>\n",
       "      <td>280.926600</td>\n",
       "      <td>279.991138</td>\n",
       "      <td>281.472435</td>\n",
       "      <td>-0.275550</td>\n",
       "      <td>0.098192</td>\n",
       "      <td>284.636266</td>\n",
       "      <td>0.403967</td>\n",
       "      <td>-5.961995</td>\n",
       "      <td>-4.500835</td>\n",
       "      <td>1.502478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-03 18:00:00</td>\n",
       "      <td>562.50</td>\n",
       "      <td>2.505664e+06</td>\n",
       "      <td>6.646282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.070830e+06</td>\n",
       "      <td>2.342437</td>\n",
       "      <td>2.432369</td>\n",
       "      <td>-0.971249</td>\n",
       "      <td>0.553060</td>\n",
       "      <td>...</td>\n",
       "      <td>277.363875</td>\n",
       "      <td>280.576898</td>\n",
       "      <td>281.473265</td>\n",
       "      <td>-0.056553</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>284.620232</td>\n",
       "      <td>0.403808</td>\n",
       "      <td>-5.987860</td>\n",
       "      <td>-3.392324</td>\n",
       "      <td>2.131114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005-01-04 00:00:00</td>\n",
       "      <td>232.30</td>\n",
       "      <td>2.505768e+06</td>\n",
       "      <td>6.125948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.094100e+06</td>\n",
       "      <td>2.342045</td>\n",
       "      <td>2.432235</td>\n",
       "      <td>-0.153568</td>\n",
       "      <td>1.554043</td>\n",
       "      <td>...</td>\n",
       "      <td>274.850965</td>\n",
       "      <td>279.654761</td>\n",
       "      <td>281.464691</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.144389</td>\n",
       "      <td>284.603425</td>\n",
       "      <td>0.404758</td>\n",
       "      <td>-5.957546</td>\n",
       "      <td>0.190590</td>\n",
       "      <td>5.349629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2005-01-04 06:00:00</td>\n",
       "      <td>329.95</td>\n",
       "      <td>2.503477e+06</td>\n",
       "      <td>7.038564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.264504e+06</td>\n",
       "      <td>2.341653</td>\n",
       "      <td>2.432090</td>\n",
       "      <td>1.247802</td>\n",
       "      <td>1.676775</td>\n",
       "      <td>...</td>\n",
       "      <td>275.490996</td>\n",
       "      <td>278.712132</td>\n",
       "      <td>281.416011</td>\n",
       "      <td>0.115504</td>\n",
       "      <td>0.144389</td>\n",
       "      <td>284.585652</td>\n",
       "      <td>0.406001</td>\n",
       "      <td>-5.957198</td>\n",
       "      <td>4.105168</td>\n",
       "      <td>4.612229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2005-01-04 12:00:00</td>\n",
       "      <td>960.51</td>\n",
       "      <td>2.504995e+06</td>\n",
       "      <td>7.938308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.247857e+06</td>\n",
       "      <td>2.341208</td>\n",
       "      <td>2.431944</td>\n",
       "      <td>2.582634</td>\n",
       "      <td>2.243500</td>\n",
       "      <td>...</td>\n",
       "      <td>281.785221</td>\n",
       "      <td>278.574102</td>\n",
       "      <td>281.349352</td>\n",
       "      <td>0.177567</td>\n",
       "      <td>0.201828</td>\n",
       "      <td>284.567493</td>\n",
       "      <td>0.405072</td>\n",
       "      <td>-5.981510</td>\n",
       "      <td>3.387434</td>\n",
       "      <td>3.809970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2005-01-04 18:00:00</td>\n",
       "      <td>194.62</td>\n",
       "      <td>2.503739e+06</td>\n",
       "      <td>8.447123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.525480e+06</td>\n",
       "      <td>2.340816</td>\n",
       "      <td>2.431810</td>\n",
       "      <td>1.169065</td>\n",
       "      <td>2.014377</td>\n",
       "      <td>...</td>\n",
       "      <td>280.623488</td>\n",
       "      <td>279.538769</td>\n",
       "      <td>281.309800</td>\n",
       "      <td>0.085340</td>\n",
       "      <td>0.126537</td>\n",
       "      <td>284.550879</td>\n",
       "      <td>0.405413</td>\n",
       "      <td>-5.995207</td>\n",
       "      <td>3.280716</td>\n",
       "      <td>4.545374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2005-01-05 00:00:00</td>\n",
       "      <td>358.51</td>\n",
       "      <td>2.505664e+06</td>\n",
       "      <td>8.417990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.620168e+06</td>\n",
       "      <td>2.340397</td>\n",
       "      <td>2.431665</td>\n",
       "      <td>0.808280</td>\n",
       "      <td>1.977174</td>\n",
       "      <td>...</td>\n",
       "      <td>277.964268</td>\n",
       "      <td>279.519437</td>\n",
       "      <td>281.288502</td>\n",
       "      <td>0.063358</td>\n",
       "      <td>0.111138</td>\n",
       "      <td>284.535038</td>\n",
       "      <td>0.407139</td>\n",
       "      <td>-5.965171</td>\n",
       "      <td>3.136332</td>\n",
       "      <td>4.321859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime   energy    p54.162.13  p55.162.13    cape.13  \\\n",
       "0  2005-01-02 18:00:00   402.71  2.510824e+06    9.186295  13.527577   \n",
       "1  2005-01-03 00:00:00   696.80  2.513173e+06    8.849569   6.896412   \n",
       "2  2005-01-03 06:00:00  1591.15  2.509627e+06    7.924080   4.774439   \n",
       "3  2005-01-03 12:00:00  1338.62  2.510571e+06    6.922709   0.000000   \n",
       "4  2005-01-03 18:00:00   562.50  2.505664e+06    6.646282   0.000000   \n",
       "5  2005-01-04 00:00:00   232.30  2.505768e+06    6.125948   0.000000   \n",
       "6  2005-01-04 06:00:00   329.95  2.503477e+06    7.038564   0.000000   \n",
       "7  2005-01-04 12:00:00   960.51  2.504995e+06    7.938308   0.000000   \n",
       "8  2005-01-04 18:00:00   194.62  2.503739e+06    8.447123   0.000000   \n",
       "9  2005-01-05 00:00:00   358.51  2.505664e+06    8.417990   0.000000   \n",
       "\n",
       "     p59.162.13  lai_lv.13  lai_hv.13   u10n.13   v10n.13  ...      t2m.13  \\\n",
       "0  1.386937e+06   2.344111   2.432983 -0.757587 -1.922799  ...  280.473098   \n",
       "1  1.153526e+06   2.343719   2.432838 -1.412620 -1.403011  ...  278.286616   \n",
       "2  1.098754e+06   2.343300   2.432704 -2.290185 -0.754580  ...  277.206490   \n",
       "3  1.076021e+06   2.342830   2.432514 -3.497855  1.271028  ...  280.926600   \n",
       "4  1.070830e+06   2.342437   2.432369 -0.971249  0.553060  ...  277.363875   \n",
       "5  1.094100e+06   2.342045   2.432235 -0.153568  1.554043  ...  274.850965   \n",
       "6  1.264504e+06   2.341653   2.432090  1.247802  1.676775  ...  275.490996   \n",
       "7  1.247857e+06   2.341208   2.431944  2.582634  2.243500  ...  281.785221   \n",
       "8  1.525480e+06   2.340816   2.431810  1.169065  2.014377  ...  280.623488   \n",
       "9  1.620168e+06   2.340397   2.431665  0.808280  1.977174  ...  277.964268   \n",
       "\n",
       "      stl2.13     stl3.13   iews.13   inss.13     stl4.13    fsr.13   flsr.13  \\\n",
       "0  281.042026  281.462478 -0.057958 -0.138650  284.684755  0.404731 -5.927092   \n",
       "1  280.747406  281.486541 -0.103576 -0.083050  284.667948  0.404920 -5.913881   \n",
       "2  280.114863  281.487095 -0.165721 -0.036241  284.651914  0.405704 -5.908272   \n",
       "3  279.991138  281.472435 -0.275550  0.098192  284.636266  0.403967 -5.961995   \n",
       "4  280.576898  281.473265 -0.056553  0.041844  284.620232  0.403808 -5.987860   \n",
       "5  279.654761  281.464691  0.003361  0.144389  284.603425  0.404758 -5.957546   \n",
       "6  278.712132  281.416011  0.115504  0.144389  284.585652  0.406001 -5.957198   \n",
       "7  278.574102  281.349352  0.177567  0.201828  284.567493  0.405072 -5.981510   \n",
       "8  279.538769  281.309800  0.085340  0.126537  284.550879  0.405413 -5.995207   \n",
       "9  279.519437  281.288502  0.063358  0.111138  284.535038  0.407139 -5.965171   \n",
       "\n",
       "    u100.13   v100.13  \n",
       "0 -1.780562 -4.443617  \n",
       "1 -3.743344 -3.129469  \n",
       "2 -5.097203 -1.157748  \n",
       "3 -4.500835  1.502478  \n",
       "4 -3.392324  2.131114  \n",
       "5  0.190590  5.349629  \n",
       "6  4.105168  4.612229  \n",
       "7  3.387434  3.809970  \n",
       "8  3.280716  4.545374  \n",
       "9  3.136332  4.321859  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sotavento_columns = ['datetime', 'energy']\n",
    "sotavento_columns.extend(col for col in wind_ava.columns if col.endswith(\".13\"))\n",
    "wind_ava_sotavento = wind_ava[sotavento_columns]\n",
    "wind_ava_sotavento.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Vertical integral of temperature</th>\n",
       "      <th>Vertical integral of water vapour</th>\n",
       "      <th>Convective available potential energy</th>\n",
       "      <th>Vertical integral of divergence of kinetic energy</th>\n",
       "      <th>Leaf area index, low vegetation</th>\n",
       "      <th>Leaf area index, high vegetation</th>\n",
       "      <th>Neutral wind at 10 m u-component</th>\n",
       "      <th>Neutral wind at 10 m v-component</th>\n",
       "      <th>...</th>\n",
       "      <th>2 metre temperature</th>\n",
       "      <th>Soil temperature level 2</th>\n",
       "      <th>Soil temperature level 3</th>\n",
       "      <th>Instantaneous eastward turbulent surface stress</th>\n",
       "      <th>Instantaneous northward turbulent surface</th>\n",
       "      <th>Soil temperature level 4</th>\n",
       "      <th>Forecast surface roughness</th>\n",
       "      <th>Forecast logarithm of surface roughness for heat</th>\n",
       "      <th>100 metre U wind component</th>\n",
       "      <th>100 metre V wind component</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-02 18:00:00</td>\n",
       "      <td>402.71</td>\n",
       "      <td>2.510824e+06</td>\n",
       "      <td>9.186295</td>\n",
       "      <td>13.527577</td>\n",
       "      <td>1.386937e+06</td>\n",
       "      <td>2.344111</td>\n",
       "      <td>2.432983</td>\n",
       "      <td>-0.757587</td>\n",
       "      <td>-1.922799</td>\n",
       "      <td>...</td>\n",
       "      <td>280.473098</td>\n",
       "      <td>281.042026</td>\n",
       "      <td>281.462478</td>\n",
       "      <td>-0.057958</td>\n",
       "      <td>-0.138650</td>\n",
       "      <td>284.684755</td>\n",
       "      <td>0.404731</td>\n",
       "      <td>-5.927092</td>\n",
       "      <td>-1.780562</td>\n",
       "      <td>-4.443617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-03 00:00:00</td>\n",
       "      <td>696.80</td>\n",
       "      <td>2.513173e+06</td>\n",
       "      <td>8.849569</td>\n",
       "      <td>6.896412</td>\n",
       "      <td>1.153526e+06</td>\n",
       "      <td>2.343719</td>\n",
       "      <td>2.432838</td>\n",
       "      <td>-1.412620</td>\n",
       "      <td>-1.403011</td>\n",
       "      <td>...</td>\n",
       "      <td>278.286616</td>\n",
       "      <td>280.747406</td>\n",
       "      <td>281.486541</td>\n",
       "      <td>-0.103576</td>\n",
       "      <td>-0.083050</td>\n",
       "      <td>284.667948</td>\n",
       "      <td>0.404920</td>\n",
       "      <td>-5.913881</td>\n",
       "      <td>-3.743344</td>\n",
       "      <td>-3.129469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-03 06:00:00</td>\n",
       "      <td>1591.15</td>\n",
       "      <td>2.509627e+06</td>\n",
       "      <td>7.924080</td>\n",
       "      <td>4.774439</td>\n",
       "      <td>1.098754e+06</td>\n",
       "      <td>2.343300</td>\n",
       "      <td>2.432704</td>\n",
       "      <td>-2.290185</td>\n",
       "      <td>-0.754580</td>\n",
       "      <td>...</td>\n",
       "      <td>277.206490</td>\n",
       "      <td>280.114863</td>\n",
       "      <td>281.487095</td>\n",
       "      <td>-0.165721</td>\n",
       "      <td>-0.036241</td>\n",
       "      <td>284.651914</td>\n",
       "      <td>0.405704</td>\n",
       "      <td>-5.908272</td>\n",
       "      <td>-5.097203</td>\n",
       "      <td>-1.157748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-03 12:00:00</td>\n",
       "      <td>1338.62</td>\n",
       "      <td>2.510571e+06</td>\n",
       "      <td>6.922709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.076021e+06</td>\n",
       "      <td>2.342830</td>\n",
       "      <td>2.432514</td>\n",
       "      <td>-3.497855</td>\n",
       "      <td>1.271028</td>\n",
       "      <td>...</td>\n",
       "      <td>280.926600</td>\n",
       "      <td>279.991138</td>\n",
       "      <td>281.472435</td>\n",
       "      <td>-0.275550</td>\n",
       "      <td>0.098192</td>\n",
       "      <td>284.636266</td>\n",
       "      <td>0.403967</td>\n",
       "      <td>-5.961995</td>\n",
       "      <td>-4.500835</td>\n",
       "      <td>1.502478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-03 18:00:00</td>\n",
       "      <td>562.50</td>\n",
       "      <td>2.505664e+06</td>\n",
       "      <td>6.646282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.070830e+06</td>\n",
       "      <td>2.342437</td>\n",
       "      <td>2.432369</td>\n",
       "      <td>-0.971249</td>\n",
       "      <td>0.553060</td>\n",
       "      <td>...</td>\n",
       "      <td>277.363875</td>\n",
       "      <td>280.576898</td>\n",
       "      <td>281.473265</td>\n",
       "      <td>-0.056553</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>284.620232</td>\n",
       "      <td>0.403808</td>\n",
       "      <td>-5.987860</td>\n",
       "      <td>-3.392324</td>\n",
       "      <td>2.131114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime   Energy  Vertical integral of temperature  \\\n",
       "0  2005-01-02 18:00:00   402.71                      2.510824e+06   \n",
       "1  2005-01-03 00:00:00   696.80                      2.513173e+06   \n",
       "2  2005-01-03 06:00:00  1591.15                      2.509627e+06   \n",
       "3  2005-01-03 12:00:00  1338.62                      2.510571e+06   \n",
       "4  2005-01-03 18:00:00   562.50                      2.505664e+06   \n",
       "\n",
       "   Vertical integral of water vapour  Convective available potential energy  \\\n",
       "0                           9.186295                              13.527577   \n",
       "1                           8.849569                               6.896412   \n",
       "2                           7.924080                               4.774439   \n",
       "3                           6.922709                               0.000000   \n",
       "4                           6.646282                               0.000000   \n",
       "\n",
       "   Vertical integral of divergence of kinetic energy  \\\n",
       "0                                       1.386937e+06   \n",
       "1                                       1.153526e+06   \n",
       "2                                       1.098754e+06   \n",
       "3                                       1.076021e+06   \n",
       "4                                       1.070830e+06   \n",
       "\n",
       "   Leaf area index, low vegetation  Leaf area index, high vegetation  \\\n",
       "0                         2.344111                          2.432983   \n",
       "1                         2.343719                          2.432838   \n",
       "2                         2.343300                          2.432704   \n",
       "3                         2.342830                          2.432514   \n",
       "4                         2.342437                          2.432369   \n",
       "\n",
       "   Neutral wind at 10 m u-component  Neutral wind at 10 m v-component  ...  \\\n",
       "0                         -0.757587                         -1.922799  ...   \n",
       "1                         -1.412620                         -1.403011  ...   \n",
       "2                         -2.290185                         -0.754580  ...   \n",
       "3                         -3.497855                          1.271028  ...   \n",
       "4                         -0.971249                          0.553060  ...   \n",
       "\n",
       "   2 metre temperature  Soil temperature level 2  Soil temperature level 3  \\\n",
       "0           280.473098                281.042026                281.462478   \n",
       "1           278.286616                280.747406                281.486541   \n",
       "2           277.206490                280.114863                281.487095   \n",
       "3           280.926600                279.991138                281.472435   \n",
       "4           277.363875                280.576898                281.473265   \n",
       "\n",
       "   Instantaneous eastward turbulent surface stress  \\\n",
       "0                                        -0.057958   \n",
       "1                                        -0.103576   \n",
       "2                                        -0.165721   \n",
       "3                                        -0.275550   \n",
       "4                                        -0.056553   \n",
       "\n",
       "   Instantaneous northward turbulent surface  Soil temperature level 4  \\\n",
       "0                                  -0.138650                284.684755   \n",
       "1                                  -0.083050                284.667948   \n",
       "2                                  -0.036241                284.651914   \n",
       "3                                   0.098192                284.636266   \n",
       "4                                   0.041844                284.620232   \n",
       "\n",
       "   Forecast surface roughness  \\\n",
       "0                    0.404731   \n",
       "1                    0.404920   \n",
       "2                    0.405704   \n",
       "3                    0.403967   \n",
       "4                    0.403808   \n",
       "\n",
       "   Forecast logarithm of surface roughness for heat  \\\n",
       "0                                         -5.927092   \n",
       "1                                         -5.913881   \n",
       "2                                         -5.908272   \n",
       "3                                         -5.961995   \n",
       "4                                         -5.987860   \n",
       "\n",
       "   100 metre U wind component  100 metre V wind component  \n",
       "0                   -1.780562                   -4.443617  \n",
       "1                   -3.743344                   -3.129469  \n",
       "2                   -5.097203                   -1.157748  \n",
       "3                   -4.500835                    1.502478  \n",
       "4                   -3.392324                    2.131114  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_ava_sotavento = wind_ava_sotavento.rename(columns = {\n",
    "    \"datetime\": \"Datetime\",\n",
    "    \"energy\": \"Energy\",\n",
    "    \"p54.162.13\": \"Vertical integral of temperature\", \n",
    "    \"p55.162.13\": \"Vertical integral of water vapour\", \n",
    "    \"cape.13\": \"Convective available potential energy\", \n",
    "    \"p59.162.13\": \"Vertical integral of divergence of kinetic energy\", \n",
    "    \"lai_lv.13\": \"Leaf area index, low vegetation\", \n",
    "    \"lai_hv.13\": \"Leaf area index, high vegetation\", \n",
    "    \"u10n.13\": \"Neutral wind at 10 m u-component\", \n",
    "    \"v10n.13\": \"Neutral wind at 10 m v-component\", \n",
    "    \"sp.13\": \"Surface pressure\",\n",
    "    \"stl1.13\": \"Soil temperature level 1\",\n",
    "    \"u10.13\": \"10 metre U wind component\",\n",
    "    \"v10.13\": \"10 metre V wind component\",\n",
    "    \"t2m.13\": \"2 metre temperature\", \n",
    "    \"stl2.13\": \"Soil temperature level 2\", \n",
    "    \"stl3.13\": \"Soil temperature level 3\", \n",
    "    \"iews.13\": \"Instantaneous eastward turbulent surface stress\",\n",
    "    \"inss.13\": \"Instantaneous northward turbulent surface\", \n",
    "    \"stl4.13\": \"Soil temperature level 4\", \n",
    "    \"fsr.13\": \"Forecast surface roughness\", \n",
    "    \"flsr.13\": \"Forecast logarithm of surface roughness for heat\",\n",
    "    \"u100.13\": \"100 metre U wind component\",\n",
    "    \"v100.13\": \"100 metre V wind component\", })\n",
    "wind_ava_sotavento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tercer cuartil es: 1089.375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Vertical integral of temperature</th>\n",
       "      <th>Vertical integral of water vapour</th>\n",
       "      <th>Convective available potential energy</th>\n",
       "      <th>Vertical integral of divergence of kinetic energy</th>\n",
       "      <th>Leaf area index, low vegetation</th>\n",
       "      <th>Leaf area index, high vegetation</th>\n",
       "      <th>Neutral wind at 10 m u-component</th>\n",
       "      <th>Neutral wind at 10 m v-component</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil temperature level 2</th>\n",
       "      <th>Soil temperature level 3</th>\n",
       "      <th>Instantaneous eastward turbulent surface stress</th>\n",
       "      <th>Instantaneous northward turbulent surface</th>\n",
       "      <th>Soil temperature level 4</th>\n",
       "      <th>Forecast surface roughness</th>\n",
       "      <th>Forecast logarithm of surface roughness for heat</th>\n",
       "      <th>100 metre U wind component</th>\n",
       "      <th>100 metre V wind component</th>\n",
       "      <th>Energy_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-02 18:00:00</td>\n",
       "      <td>402.71</td>\n",
       "      <td>2.510824e+06</td>\n",
       "      <td>9.186295</td>\n",
       "      <td>13.527577</td>\n",
       "      <td>1.386937e+06</td>\n",
       "      <td>2.344111</td>\n",
       "      <td>2.432983</td>\n",
       "      <td>-0.757587</td>\n",
       "      <td>-1.922799</td>\n",
       "      <td>...</td>\n",
       "      <td>281.042026</td>\n",
       "      <td>281.462478</td>\n",
       "      <td>-0.057958</td>\n",
       "      <td>-0.138650</td>\n",
       "      <td>284.684755</td>\n",
       "      <td>0.404731</td>\n",
       "      <td>-5.927092</td>\n",
       "      <td>-1.780562</td>\n",
       "      <td>-4.443617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-03 00:00:00</td>\n",
       "      <td>696.80</td>\n",
       "      <td>2.513173e+06</td>\n",
       "      <td>8.849569</td>\n",
       "      <td>6.896412</td>\n",
       "      <td>1.153526e+06</td>\n",
       "      <td>2.343719</td>\n",
       "      <td>2.432838</td>\n",
       "      <td>-1.412620</td>\n",
       "      <td>-1.403011</td>\n",
       "      <td>...</td>\n",
       "      <td>280.747406</td>\n",
       "      <td>281.486541</td>\n",
       "      <td>-0.103576</td>\n",
       "      <td>-0.083050</td>\n",
       "      <td>284.667948</td>\n",
       "      <td>0.404920</td>\n",
       "      <td>-5.913881</td>\n",
       "      <td>-3.743344</td>\n",
       "      <td>-3.129469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-03 06:00:00</td>\n",
       "      <td>1591.15</td>\n",
       "      <td>2.509627e+06</td>\n",
       "      <td>7.924080</td>\n",
       "      <td>4.774439</td>\n",
       "      <td>1.098754e+06</td>\n",
       "      <td>2.343300</td>\n",
       "      <td>2.432704</td>\n",
       "      <td>-2.290185</td>\n",
       "      <td>-0.754580</td>\n",
       "      <td>...</td>\n",
       "      <td>280.114863</td>\n",
       "      <td>281.487095</td>\n",
       "      <td>-0.165721</td>\n",
       "      <td>-0.036241</td>\n",
       "      <td>284.651914</td>\n",
       "      <td>0.405704</td>\n",
       "      <td>-5.908272</td>\n",
       "      <td>-5.097203</td>\n",
       "      <td>-1.157748</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-03 12:00:00</td>\n",
       "      <td>1338.62</td>\n",
       "      <td>2.510571e+06</td>\n",
       "      <td>6.922709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.076021e+06</td>\n",
       "      <td>2.342830</td>\n",
       "      <td>2.432514</td>\n",
       "      <td>-3.497855</td>\n",
       "      <td>1.271028</td>\n",
       "      <td>...</td>\n",
       "      <td>279.991138</td>\n",
       "      <td>281.472435</td>\n",
       "      <td>-0.275550</td>\n",
       "      <td>0.098192</td>\n",
       "      <td>284.636266</td>\n",
       "      <td>0.403967</td>\n",
       "      <td>-5.961995</td>\n",
       "      <td>-4.500835</td>\n",
       "      <td>1.502478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-03 18:00:00</td>\n",
       "      <td>562.50</td>\n",
       "      <td>2.505664e+06</td>\n",
       "      <td>6.646282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.070830e+06</td>\n",
       "      <td>2.342437</td>\n",
       "      <td>2.432369</td>\n",
       "      <td>-0.971249</td>\n",
       "      <td>0.553060</td>\n",
       "      <td>...</td>\n",
       "      <td>280.576898</td>\n",
       "      <td>281.473265</td>\n",
       "      <td>-0.056553</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>284.620232</td>\n",
       "      <td>0.403808</td>\n",
       "      <td>-5.987860</td>\n",
       "      <td>-3.392324</td>\n",
       "      <td>2.131114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005-01-04 00:00:00</td>\n",
       "      <td>232.30</td>\n",
       "      <td>2.505768e+06</td>\n",
       "      <td>6.125948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.094100e+06</td>\n",
       "      <td>2.342045</td>\n",
       "      <td>2.432235</td>\n",
       "      <td>-0.153568</td>\n",
       "      <td>1.554043</td>\n",
       "      <td>...</td>\n",
       "      <td>279.654761</td>\n",
       "      <td>281.464691</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.144389</td>\n",
       "      <td>284.603425</td>\n",
       "      <td>0.404758</td>\n",
       "      <td>-5.957546</td>\n",
       "      <td>0.190590</td>\n",
       "      <td>5.349629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2005-01-04 06:00:00</td>\n",
       "      <td>329.95</td>\n",
       "      <td>2.503477e+06</td>\n",
       "      <td>7.038564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.264504e+06</td>\n",
       "      <td>2.341653</td>\n",
       "      <td>2.432090</td>\n",
       "      <td>1.247802</td>\n",
       "      <td>1.676775</td>\n",
       "      <td>...</td>\n",
       "      <td>278.712132</td>\n",
       "      <td>281.416011</td>\n",
       "      <td>0.115504</td>\n",
       "      <td>0.144389</td>\n",
       "      <td>284.585652</td>\n",
       "      <td>0.406001</td>\n",
       "      <td>-5.957198</td>\n",
       "      <td>4.105168</td>\n",
       "      <td>4.612229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2005-01-04 12:00:00</td>\n",
       "      <td>960.51</td>\n",
       "      <td>2.504995e+06</td>\n",
       "      <td>7.938308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.247857e+06</td>\n",
       "      <td>2.341208</td>\n",
       "      <td>2.431944</td>\n",
       "      <td>2.582634</td>\n",
       "      <td>2.243500</td>\n",
       "      <td>...</td>\n",
       "      <td>278.574102</td>\n",
       "      <td>281.349352</td>\n",
       "      <td>0.177567</td>\n",
       "      <td>0.201828</td>\n",
       "      <td>284.567493</td>\n",
       "      <td>0.405072</td>\n",
       "      <td>-5.981510</td>\n",
       "      <td>3.387434</td>\n",
       "      <td>3.809970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2005-01-04 18:00:00</td>\n",
       "      <td>194.62</td>\n",
       "      <td>2.503739e+06</td>\n",
       "      <td>8.447123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.525480e+06</td>\n",
       "      <td>2.340816</td>\n",
       "      <td>2.431810</td>\n",
       "      <td>1.169065</td>\n",
       "      <td>2.014377</td>\n",
       "      <td>...</td>\n",
       "      <td>279.538769</td>\n",
       "      <td>281.309800</td>\n",
       "      <td>0.085340</td>\n",
       "      <td>0.126537</td>\n",
       "      <td>284.550879</td>\n",
       "      <td>0.405413</td>\n",
       "      <td>-5.995207</td>\n",
       "      <td>3.280716</td>\n",
       "      <td>4.545374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2005-01-05 00:00:00</td>\n",
       "      <td>358.51</td>\n",
       "      <td>2.505664e+06</td>\n",
       "      <td>8.417990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.620168e+06</td>\n",
       "      <td>2.340397</td>\n",
       "      <td>2.431665</td>\n",
       "      <td>0.808280</td>\n",
       "      <td>1.977174</td>\n",
       "      <td>...</td>\n",
       "      <td>279.519437</td>\n",
       "      <td>281.288502</td>\n",
       "      <td>0.063358</td>\n",
       "      <td>0.111138</td>\n",
       "      <td>284.535038</td>\n",
       "      <td>0.407139</td>\n",
       "      <td>-5.965171</td>\n",
       "      <td>3.136332</td>\n",
       "      <td>4.321859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime   Energy  Vertical integral of temperature  \\\n",
       "0  2005-01-02 18:00:00   402.71                      2.510824e+06   \n",
       "1  2005-01-03 00:00:00   696.80                      2.513173e+06   \n",
       "2  2005-01-03 06:00:00  1591.15                      2.509627e+06   \n",
       "3  2005-01-03 12:00:00  1338.62                      2.510571e+06   \n",
       "4  2005-01-03 18:00:00   562.50                      2.505664e+06   \n",
       "5  2005-01-04 00:00:00   232.30                      2.505768e+06   \n",
       "6  2005-01-04 06:00:00   329.95                      2.503477e+06   \n",
       "7  2005-01-04 12:00:00   960.51                      2.504995e+06   \n",
       "8  2005-01-04 18:00:00   194.62                      2.503739e+06   \n",
       "9  2005-01-05 00:00:00   358.51                      2.505664e+06   \n",
       "\n",
       "   Vertical integral of water vapour  Convective available potential energy  \\\n",
       "0                           9.186295                              13.527577   \n",
       "1                           8.849569                               6.896412   \n",
       "2                           7.924080                               4.774439   \n",
       "3                           6.922709                               0.000000   \n",
       "4                           6.646282                               0.000000   \n",
       "5                           6.125948                               0.000000   \n",
       "6                           7.038564                               0.000000   \n",
       "7                           7.938308                               0.000000   \n",
       "8                           8.447123                               0.000000   \n",
       "9                           8.417990                               0.000000   \n",
       "\n",
       "   Vertical integral of divergence of kinetic energy  \\\n",
       "0                                       1.386937e+06   \n",
       "1                                       1.153526e+06   \n",
       "2                                       1.098754e+06   \n",
       "3                                       1.076021e+06   \n",
       "4                                       1.070830e+06   \n",
       "5                                       1.094100e+06   \n",
       "6                                       1.264504e+06   \n",
       "7                                       1.247857e+06   \n",
       "8                                       1.525480e+06   \n",
       "9                                       1.620168e+06   \n",
       "\n",
       "   Leaf area index, low vegetation  Leaf area index, high vegetation  \\\n",
       "0                         2.344111                          2.432983   \n",
       "1                         2.343719                          2.432838   \n",
       "2                         2.343300                          2.432704   \n",
       "3                         2.342830                          2.432514   \n",
       "4                         2.342437                          2.432369   \n",
       "5                         2.342045                          2.432235   \n",
       "6                         2.341653                          2.432090   \n",
       "7                         2.341208                          2.431944   \n",
       "8                         2.340816                          2.431810   \n",
       "9                         2.340397                          2.431665   \n",
       "\n",
       "   Neutral wind at 10 m u-component  Neutral wind at 10 m v-component  ...  \\\n",
       "0                         -0.757587                         -1.922799  ...   \n",
       "1                         -1.412620                         -1.403011  ...   \n",
       "2                         -2.290185                         -0.754580  ...   \n",
       "3                         -3.497855                          1.271028  ...   \n",
       "4                         -0.971249                          0.553060  ...   \n",
       "5                         -0.153568                          1.554043  ...   \n",
       "6                          1.247802                          1.676775  ...   \n",
       "7                          2.582634                          2.243500  ...   \n",
       "8                          1.169065                          2.014377  ...   \n",
       "9                          0.808280                          1.977174  ...   \n",
       "\n",
       "   Soil temperature level 2  Soil temperature level 3  \\\n",
       "0                281.042026                281.462478   \n",
       "1                280.747406                281.486541   \n",
       "2                280.114863                281.487095   \n",
       "3                279.991138                281.472435   \n",
       "4                280.576898                281.473265   \n",
       "5                279.654761                281.464691   \n",
       "6                278.712132                281.416011   \n",
       "7                278.574102                281.349352   \n",
       "8                279.538769                281.309800   \n",
       "9                279.519437                281.288502   \n",
       "\n",
       "   Instantaneous eastward turbulent surface stress  \\\n",
       "0                                        -0.057958   \n",
       "1                                        -0.103576   \n",
       "2                                        -0.165721   \n",
       "3                                        -0.275550   \n",
       "4                                        -0.056553   \n",
       "5                                         0.003361   \n",
       "6                                         0.115504   \n",
       "7                                         0.177567   \n",
       "8                                         0.085340   \n",
       "9                                         0.063358   \n",
       "\n",
       "   Instantaneous northward turbulent surface  Soil temperature level 4  \\\n",
       "0                                  -0.138650                284.684755   \n",
       "1                                  -0.083050                284.667948   \n",
       "2                                  -0.036241                284.651914   \n",
       "3                                   0.098192                284.636266   \n",
       "4                                   0.041844                284.620232   \n",
       "5                                   0.144389                284.603425   \n",
       "6                                   0.144389                284.585652   \n",
       "7                                   0.201828                284.567493   \n",
       "8                                   0.126537                284.550879   \n",
       "9                                   0.111138                284.535038   \n",
       "\n",
       "   Forecast surface roughness  \\\n",
       "0                    0.404731   \n",
       "1                    0.404920   \n",
       "2                    0.405704   \n",
       "3                    0.403967   \n",
       "4                    0.403808   \n",
       "5                    0.404758   \n",
       "6                    0.406001   \n",
       "7                    0.405072   \n",
       "8                    0.405413   \n",
       "9                    0.407139   \n",
       "\n",
       "   Forecast logarithm of surface roughness for heat  \\\n",
       "0                                         -5.927092   \n",
       "1                                         -5.913881   \n",
       "2                                         -5.908272   \n",
       "3                                         -5.961995   \n",
       "4                                         -5.987860   \n",
       "5                                         -5.957546   \n",
       "6                                         -5.957198   \n",
       "7                                         -5.981510   \n",
       "8                                         -5.995207   \n",
       "9                                         -5.965171   \n",
       "\n",
       "   100 metre U wind component  100 metre V wind component  Energy_Class  \n",
       "0                   -1.780562                   -4.443617             0  \n",
       "1                   -3.743344                   -3.129469             0  \n",
       "2                   -5.097203                   -1.157748             1  \n",
       "3                   -4.500835                    1.502478             1  \n",
       "4                   -3.392324                    2.131114             0  \n",
       "5                    0.190590                    5.349629             0  \n",
       "6                    4.105168                    4.612229             0  \n",
       "7                    3.387434                    3.809970             0  \n",
       "8                    3.280716                    4.545374             0  \n",
       "9                    3.136332                    4.321859             0  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classificate_energy(value):\n",
    "    if value <= tercer_cuartil:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "tercer_cuartil = wind_ava_sotavento[\"Energy\"].quantile(0.75)\n",
    "wind_ava_sotavento[\"Energy_Class\"] = wind_ava_sotavento[\"Energy\"].apply(classificate_energy)\n",
    "print(\"El tercer cuartil es:\", tercer_cuartil)  \n",
    "\n",
    "wind_ava_sotavento.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos la forma de partir los datos, a una más sencilla con respecto al modelo de clasficación. Extrae los datos con la misma precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wind_ava_sotavento.iloc[:, 2:24]\n",
    "Y = wind_ava_sotavento.iloc[:, 24]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1099, random_state=100472097, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MÉTRICAS SELECCIONADAS:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas seleccionadas  para evaluar y comparar los modelos son una medida cuantitativa del rendimiento del modelo en la tarea de clasificación. Aquí hay una explicación de por qué elegimos cada una de ellas:\n",
    "\n",
    "1. **Accuracy (Precisión)**:\n",
    "   - Es una medida general de la capacidad del modelo para clasificar correctamente las instancias en todas las clases.\n",
    "   - Es fácil de interpretar y entender: simplemente indica la proporción de predicciones correctas sobre el total de predicciones.\n",
    "\n",
    "2. **Recall (Sensibilidad o True Positive Rate)**:\n",
    "   - Mide la proporción de instancias positivas reales que fueron correctamente identificadas por el modelo.\n",
    "   - Es importante en situaciones donde la identificación de instancias positivas es crítica y queremos minimizar los falsos negativos.\n",
    "\n",
    "3. **True Negative Rate (Especificidad)**:\n",
    "   - Mide la proporción de instancias negativas reales que fueron correctamente identificadas por el modelo.\n",
    "   - Es importante en situaciones donde la identificación de instancias negativas es crítica y queremos minimizar los falsos positivos.\n",
    "\n",
    "4. **Balanced Accuracy (Precisión equilibrada)**:\n",
    "   - Es la media de la sensibilidad y la especificidad, proporcionando una visión equilibrada del rendimiento del modelo en todas las clases.\n",
    "   - Es útil cuando las clases están desequilibradas y queremos asegurarnos de que el modelo funcione bien en todas las clases.\n",
    "\n",
    "5. **F1 Score**:\n",
    "   - Es una medida que combina precisión y recall en una sola métrica, proporcionando una evaluación general del rendimiento del modelo.\n",
    "   - Es útil cuando hay un desequilibrio entre las clases o cuando queremos un balance entre precisión y recall.\n",
    "\n",
    "En resumen, estas métricas nos dan una comprensión completa del rendimiento del modelo en términos de su capacidad para clasificar correctamente las instancias positivas y negativas, así como su equilibrio general entre precisión y recall. Utilizamos estas métricas para comparar y determinar cuál modelo tiene el mejor rendimiento en la tarea de clasificación específica que estamos abordando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MEJOR MODELO A MODELO DE CLASIFICACIÓN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que hacemos en esta sección es con el mejor modelo que obtuvimos en regresión lo pasamos a clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOBRE EL BALANCEADO:\n",
    "\n",
    "En el contexto de la clasificación binaria, esto significa que el número de ejemplos en cada clase (positiva y negativa) es aproximadamente el mismo o está ajustado de manera que el modelo no esté sesgado hacia una clase dominante.\n",
    "\n",
    "Cuando no se balancea el modelo, el conjunto de datos puede tener una distribución desigual de las clases, lo que puede llevar a que el modelo aprenda de manera sesgada, dando más peso o importancia a la clase dominante y menos a la clase minoritaria. Esto puede resultar en un modelo que tiene un buen rendimiento en términos de métricas globales (como la precisión) pero puede tener un rendimiento deficiente en la detección de la clase minoritaria.\n",
    "\n",
    "Cuando se balancea el modelo, se pueden aplicar diferentes técnicas, como:\n",
    "\n",
    "1. **Submuestreo de la clase dominante**: Reducir aleatoriamente el número de ejemplos de la clase dominante para que esté más equilibrado con la clase minoritaria.\n",
    "\n",
    "2. **Sobremuestreo de la clase minoritaria**: Aumentar aleatoriamente el número de ejemplos de la clase minoritaria para equilibrar las clases.\n",
    "\n",
    "3. **Generación sintética de muestras**: Crear nuevos ejemplos sintéticos para la clase minoritaria utilizando técnicas como SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "\n",
    "4. **Peso de clase**: Dar pesos diferentes a las clases durante el entrenamiento del modelo para compensar el desequilibrio de clases.\n",
    "\n",
    "Por lo que lo que nosotras intendimos es que la diferencia principal entre balancear y no balancear el modelo es que, al balancearlo, se intenta reducir el impacto del desequilibrio de clases en el rendimiento del modelo, especialmente en la capacidad de generalización para predecir correctamente las clases minoritarias. Por otro lado, si no se balancea el modelo, existe el riesgo de que el modelo esté sesgado hacia la clase dominante y tenga un rendimiento deficiente en la clasificación de la clase minoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC con ajuste de hiperparámetros sin balancear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se buscan los mejores hiperparámetros para un clasificador SVM utilizando una validación cruzada de 5-fold y luego evalúa el rendimiento del modelo con las métricas seleccionadas en un conjunto de datos de prueba. Para este primer modelo el clasificacion no se balancea, pero si se ajustan hiperparametros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mejores hiperparametros son: {'svc__C': 10, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Accuracy:  0.8717015468607825\n",
      "Recall:  0.6549295774647887\n",
      "True Negative Rate:  0.947239263803681\n",
      "True Positive Rate:  0.6549295774647887\n",
      "Balanced Accurancy:  0.8010844206342349\n",
      "F1 Score:  0.8669178411387228\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "svc = SVC(random_state = 100472097)\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "clf_hpo = Pipeline(steps=[('scaler', scaler), ('svc', svc)])\n",
    "\n",
    "slf_hpo_params = {'svc__C': [0.1, 1, 10], 'svc__gamma': [1, 0.1, 0.01, 10, 100], 'svc__kernel': ['linear','rbf']}\n",
    "\n",
    "clf_hpo = GridSearchCV(clf_hpo, slf_hpo_params, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "clf_hpo.fit(x_train_scaled, y_train)\n",
    "y_pred = clf_hpo.predict(x_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "tnr = recall_score(y_test, y_pred, pos_label=0)\n",
    "tpr = recall_score(y_test, y_pred, pos_label=1)\n",
    "balanced_accurancy = balanced_accuracy_score(y_test, y_pred)\n",
    "f1_1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Los mejores hiperparametros son:', clf_hpo.best_params_)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"True Negative Rate: \", tnr)  \n",
    "print(\"True Positive Rate: \", tpr)\n",
    "print(\"Balanced Accurancy: \", balanced_accurancy)\n",
    "print(\"F1 Score: \", f1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC sin ajuste de hiperparámetros y balanceado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado no se incluyem consideraciones específicas de balanceamiento de clases. Y además no se ajustan hiperaparametros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8671519563239308\n",
      "Recall:  0.6619718309859155\n",
      "True Negative Rate:  0.6619718309859155\n",
      "True Positive Rate:  0.9386503067484663\n",
      "Balanced Accurancy:  0.8003110688671908\n",
      "F1 Score:  0.8631215921389412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "scaler = StandardScaler()\n",
    "svc = SVC(random_state = 100472097)\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "clf_hpo = Pipeline(steps=[('scaler', scaler), ('svc', svc)])\n",
    "\n",
    "clf_hpo.fit(x_train_scaled, y_train)\n",
    "y_pred = clf_hpo.predict(x_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "tnr = recall_score(y_test, y_pred, pos_label=1)\n",
    "tpr = recall_score(y_test, y_pred, pos_label=0)\n",
    "balanced_accurancy = balanced_accuracy_score(y_test, y_pred)\n",
    "f1_1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"True Negative Rate: \", tnr)  \n",
    "print(\"True Positive Rate: \", tpr)\n",
    "print(\"Balanced Accurancy: \", balanced_accurancy)\n",
    "print(\"F1 Score: \", f1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC con ajuste de hiperparámetros y balanceado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se implementa un proceso de ajuste de hiperparámetros para un modelo de clasificación utilizando SVM (Support Vector Machine) con consideraciones de balanceamiento de clases y validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mejores hiperparametros son: {'svc__C': 1, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Accuracy:  0.8471337579617835\n",
      "Recall:  0.8133802816901409\n",
      "True Negative Rate:  0.8588957055214724\n",
      "True Positive Rate:  0.8133802816901409\n",
      "Balanced Accurancy:  0.8361379936058067\n",
      "F1 Score:  0.8516335196498982\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "svc = SVC(class_weight='balanced', random_state = 100472097)\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "clf_hpo = Pipeline(steps=[('scaler', scaler), ('svc', svc)])\n",
    "\n",
    "slf_hpo_params = {'svc__C': [0.1, 1, 10], 'svc__gamma': [1, 0.1, 0.01, 10, 100], 'svc__kernel': ['linear','rbf']}\n",
    "\n",
    "clf_hpo = GridSearchCV(clf_hpo, slf_hpo_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "clf_hpo.fit(x_train_scaled, y_train)\n",
    "y_pred = clf_hpo.predict(x_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "tnr = recall_score(y_test, y_pred, pos_label=0)\n",
    "tpr = recall_score(y_test, y_pred, pos_label=1)\n",
    "balanced_accurancy = balanced_accuracy_score(y_test, y_pred)\n",
    "f1_1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Los mejores hiperparametros son:', clf_hpo.best_params_)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"True Negative Rate: \", tnr)  \n",
    "print(\"True Positive Rate: \", tpr)\n",
    "print(\"Balanced Accurancy: \", balanced_accurancy)\n",
    "print(\"F1 Score: \", f1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Matriz de confusión en SVM***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión es una herramienta útil para comprender el rendimiento del modelo en la clasificación de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class Pred 0  Class Pred 1\n",
      "Real 0            700           115\n",
      "Real 1             53           231\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index = [\"Real 0\", \"Real 1\"], columns = [\" Class Pred 0\", \"Class Pred 1\"])\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretación de la matriz de confusión:\n",
    "\n",
    "Para la clase verdadera \"0\" (Real 0), el modelo predijo correctamente 700 instancias como \"0\" y erróneamente clasificó 115 instancias como \"1\".\n",
    "Para la clase verdadera \"1\" (Real 1), el modelo predijo correctamente 231 instancias como \"1\" y erróneamente clasificó 53 instancias como \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MODELO DE CLASIFICACIÓN KNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones tras la obtención de resultados: \n",
    "\n",
    "Estos resultados comparan el rendimiento de un modelo de clasificación KNN (K-Nearest Neighbors) antes y después de ajustar sus hiperparámetros.\n",
    "\n",
    "**Resultados del modelo sin ajuste de hiperparámetros:**\n",
    "- Accuracy: 0.844\n",
    "- Recall: 0.595\n",
    "- True Negative Rate: 0.931\n",
    "- True Positive Rate: 0.595\n",
    "- Balanced Accuracy: 0.763\n",
    "- F1 Score: 0.664\n",
    "\n",
    "**Resultados del modelo con hiperparámetros ajustados:**\n",
    "- Mejores hiperparámetros encontrados: {'knn__algorithm': 'auto', 'knn__n_neighbors': 13, 'knn__p': 1, 'knn__weights': 'distance'}\n",
    "- Accuracy: 0.863\n",
    "- Recall: 0.599\n",
    "- True Negative Rate: 0.955\n",
    "- True Positive Rate: 0.599\n",
    "- Balanced Accuracy: 0.777\n",
    "- F1 Score: 0.855\n",
    "\n",
    "Comparando los dos conjuntos de resultados:\n",
    "\n",
    "1. **Accuracy:** El modelo con hiperparámetros ajustados tiene una precisión ligeramente mayor (86.3% frente a 84.4%).\n",
    "2. **Recall y True Positive Rate:** Ambos modelos tienen un rendimiento similar en términos de recall y True Positive Rate, con una ligera mejora en el modelo con hiperparámetros ajustados.\n",
    "3. **True Negative Rate:** El modelo con hiperparámetros ajustados tiene una tasa de verdaderos negativos ligeramente mayor (95.5% frente a 93.1%).\n",
    "4. **Balanced Accuracy:** La precisión equilibrada también es ligeramente mayor en el modelo con hiperparámetros ajustados (77.7% frente a 76.3%).\n",
    "5. **F1 Score:** El modelo con hiperparámetros ajustados muestra una mejora significativa en la puntuación F1 (85.5% frente a 66.4%), lo que indica un mejor equilibrio entre precisión y recall.\n",
    "\n",
    "En resumen, ajustar los hiperparámetros del modelo KNN ha mejorado su rendimiento general, especialmente en términos de F1 Score, lo que sugiere que es una configuración más óptima para este conjunto de datos y problema de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8444040036396724\n",
      "Recall:  0.5950704225352113\n",
      "True Negative Rate:  0.9312883435582822\n",
      "True Positive Rate:  0.5950704225352113\n",
      "Balanced Accuracy:  0.7631793830467467\n",
      "F1 Score:  0.6640471512770137\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "knn_classifier.fit(x_train_scaled, y_train)\n",
    "y_pred = knn_classifier.predict(x_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "tnr = recall_score(y_test, y_pred, pos_label=0)\n",
    "tpr = recall_score(y_test, y_pred, pos_label=1)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "f1_knn = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"True Negative Rate: \", tnr)  \n",
    "print(\"True Positive Rate: \", tpr)\n",
    "print(\"Balanced Accuracy: \", balanced_accuracy)\n",
    "print(\"F1 Score: \", f1_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados: {'knn__algorithm': 'auto', 'knn__n_neighbors': 13, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "Accuracy:  0.8626023657870792\n",
      "Recall:  0.5985915492957746\n",
      "True Negative Rate:  0.9546012269938651\n",
      "True Positive Rate:  0.5985915492957746\n",
      "Balanced Accuracy:  0.7765963881448199\n",
      "F1 Score:  0.8549277163642376\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('knn', knn_classifier)])\n",
    "\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 7, 13, 15, 30],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__p': [1, 2], \n",
    "    'knn__algorithm': ['auto', 'ball_tree', 'brute', 'kd_tree']\n",
    "}\n",
    "\n",
    "knn_classifier = GridSearchCV(pipe, param_grid, cv=TimeSeriesSplit(n_splits=5))\n",
    "knn_classifier.fit(x_train_scaled, y_train)\n",
    "y_pred = knn_classifier.predict(x_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "tnr = recall_score(y_test, y_pred, pos_label=0)\n",
    "tpr = recall_score(y_test, y_pred, pos_label=1)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "f1_knn = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\", knn_classifier.best_params_)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"True Negative Rate: \", tnr)  \n",
    "print(\"True Positive Rate: \", tpr)\n",
    "print(\"Balanced Accuracy: \", balanced_accuracy)\n",
    "print(\"F1 Score: \", f1_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Matriz de confusión en KNN***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión es una herramienta útil para comprender el rendimiento del modelo en la clasificación de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class Pred 0  Class Pred 1\n",
      "Real 0            778            37\n",
      "Real 1            114           170\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index = [\"Real 0\", \"Real 1\"], columns = [\" Class Pred 0\", \"Class Pred 1\"])\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta matriz de confusión:\n",
    "\n",
    "Para la clase verdadera \"0\" (Real 0), el modelo predijo correctamente 778 instancias como \"0\" y erróneamente clasificó 37 instancias como \"1\".\n",
    "Para la clase verdadera \"1\" (Real 1), el modelo predijo correctamente 170 instancias como \"1\" y erróneamente clasificó 114 instancias como \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MODELO DE CLASIFICACIÓN ÁRBOL DE CLASIFICACIÓN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones tras la obtención de resultados:\n",
    "\n",
    "Estos resultados comparan el rendimiento de un modelo de árbol de clasificación antes y después de ajustar sus hiperparámetros.\n",
    "\n",
    "**Resultados del modelo sin ajuste de hiperparámetros:**\n",
    "- Accuracy: 0.813\n",
    "- Recall: 0.609\n",
    "- True Negative Rate: 0.883\n",
    "- True Positive Rate: 0.609\n",
    "- Balanced Accuracy: 0.746\n",
    "- F1 Score: 0.811\n",
    "\n",
    "**Resultados del modelo con hiperparámetros ajustados:**\n",
    "- Mejores hiperparámetros encontrados: {'tree__max_depth': 3, 'tree__min_samples_leaf': 2, 'tree__min_samples_split': 2}\n",
    "- Accuracy: 0.846\n",
    "- Recall: 0.680\n",
    "- True Negative Rate: 0.904\n",
    "- True Positive Rate: 0.680\n",
    "- Balanced Accuracy: 0.792\n",
    "- F1 Score: 0.845\n",
    "\n",
    "Comparando los dos conjuntos de resultados:\n",
    "\n",
    "1. **Accuracy:** El modelo con hiperparámetros ajustados tiene una precisión ligeramente mayor (84.6% frente a 81.3%).\n",
    "2. **Recall y True Positive Rate:** El modelo con hiperparámetros ajustados tiene un recall y True Positive Rate más altos (68.0% frente a 60.9%), lo que indica una mejor capacidad para identificar la clase positiva.\n",
    "3. **True Negative Rate:** El modelo con hiperparámetros ajustados también tiene una tasa de verdaderos negativos ligeramente mayor (90.4% frente a 88.3%).\n",
    "4. **Balanced Accuracy:** La precisión equilibrada también es ligeramente mayor en el modelo con hiperparámetros ajustados (79.2% frente a 74.6%).\n",
    "5. **F1 Score:** El modelo con hiperparámetros ajustados muestra una mejora en la puntuación F1 (84.5% frente a 81.1%), lo que indica un mejor equilibrio entre precisión y recall.\n",
    "\n",
    "En resumen, ajustar los hiperparámetros del modelo de árbol de clasificación ha mejorado su rendimiento general, especialmente en términos de recall, Balanced Accuracy y F1 Score, lo que sugiere que es una configuración más óptima para este conjunto de datos y problema de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8125568698817106\n",
      "Recall:  0.6091549295774648\n",
      "True Negative Rate:  0.8834355828220859\n",
      "True Positive Rate:  0.6091549295774648\n",
      "Balanced Accurancy:  0.7462952561997753\n",
      "F1 Score:  0.8107513264972266\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "tree= DecisionTreeClassifier(random_state = 100472097)\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "tree.fit(x_train_scaled, y_train)\n",
    "y_pred = tree.predict(x_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "tnr = recall_score(y_test, y_pred, pos_label=0)\n",
    "tpr = recall_score(y_test, y_pred, pos_label=1)\n",
    "balanced_accurancy = balanced_accuracy_score(y_test, y_pred)\n",
    "f1_1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"True Negative Rate: \", tnr)  \n",
    "print(\"True Positive Rate: \", tpr)\n",
    "print(\"Balanced Accurancy: \", balanced_accurancy)\n",
    "print(\"F1 Score: \", f1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados: {'tree__max_depth': 3, 'tree__min_samples_leaf': 2, 'tree__min_samples_split': 2}\n",
      "Accuracy:  0.8462238398544131\n",
      "Recall:  0.6795774647887324\n",
      "True Negative Rate:  0.9042944785276074\n",
      "True Positive Rate:  0.6795774647887324\n",
      "Balanced Accuracy:  0.7919359716581699\n",
      "F1 Score:  0.8450312236178545\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "tree= DecisionTreeClassifier(random_state = 100472097)\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('tree', tree)])\n",
    "\n",
    "param_grid = {\n",
    "    'tree__max_depth': [3, 5, 7, None],\n",
    "    'tree__min_samples_split': [2, 5, 10],\n",
    "    'tree__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "tree = GridSearchCV(pipe, param_grid, cv=TimeSeriesSplit(n_splits=5))\n",
    "tree.fit(x_train_scaled, y_train)\n",
    "y_pred = tree.predict(x_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "tnr = recall_score(y_test, y_pred, pos_label=0)\n",
    "tpr = recall_score(y_test, y_pred, pos_label=1)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\", tree.best_params_)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"True Negative Rate: \", tnr)  \n",
    "print(\"True Positive Rate: \", tpr)\n",
    "print(\"Balanced Accuracy: \", balanced_accuracy)\n",
    "print(\"F1 Score: \", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Matriz de confusión en AC***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión es una herramienta útil para comprender el rendimiento del modelo en la clasificación de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class Pred 0  Class Pred 1\n",
      "Real 0            737            78\n",
      "Real 1             91           193\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index = [\"Real 0\", \"Real 1\"], columns = [\" Class Pred 0\", \"Class Pred 1\"])\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta matriz de confusión:\n",
    "\n",
    "Para la clase verdadera \"0\" (Real 0), el modelo predijo correctamente 737 instancias como \"0\" y erróneamente clasificó 78 instancias como \"1\".\n",
    "Para la clase verdadera \"1\" (Real 1), el modelo predijo correctamente 193 instancias como \"1\" y erróneamente clasificó 91 instancias como \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MODELO REGRESION LOGISTICA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones tras la obtención de resultados:\n",
    "\n",
    "Los resultados de la regresión logística muestran que, incluso después de ajustar los hiperparámetros, no hubo una mejora significativa en las métricas de rendimiento. Aquí está el análisis comparativo:\n",
    "\n",
    "**Sin ajustes de hiperparámetros:**\n",
    "- Accuracy: 0.817\n",
    "- Recall: 0.444\n",
    "- True Negative Rate: 0.947\n",
    "- True Positive Rate: 0.444\n",
    "- Balanced Accuracy: 0.695\n",
    "- F1 Score: 0.800\n",
    "\n",
    "**Con ajustes de hiperparámetros:**\n",
    "- Mejores hiperparámetros encontrados: {'logistic_regression__C': 10, 'logistic_regression__solver': 'liblinear'}\n",
    "- Accuracy: 0.815\n",
    "- Recall: 0.444\n",
    "- True Negative Rate: 0.945\n",
    "- True Positive Rate: 0.444\n",
    "- Balanced Accuracy: 0.694\n",
    "- F1 Score: 0.798\n",
    "\n",
    "En ambos casos, los valores de las métricas de rendimiento (Accuracy, Recall, True Negative Rate, True Positive Rate, Balanced Accuracy y F1 Score) son muy similares. Esto sugiere que el ajuste de hiperparámetros no tuvo un impacto significativo en el rendimiento del modelo de regresión logística en este conjunto de datos.\n",
    "\n",
    "En resumen, los ajustes de hiperparámetros no mejoraron el rendimiento del modelo de regresión logística en este caso específico. si recordamos algo similar pasaba en Regresión Lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8171064604185623\n",
      "Recall:  0.44366197183098594\n",
      "True Negative Rate:  0.947239263803681\n",
      "True Positive Rate:  0.44366197183098594\n",
      "Balanced Accuracy:  0.6954506178173334\n",
      "F1 Score:  0.7999180747369808\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "logistic_regression = LogisticRegression(random_state=100472097)\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "logistic_regression.fit(x_train_scaled, y_train)\n",
    "y_pred = logistic_regression.predict(x_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "tnr = recall_score(y_test, y_pred, pos_label=0)\n",
    "tpr = recall_score(y_test, y_pred, pos_label=1)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "f1_score = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"True Negative Rate: \", tnr)  \n",
    "print(\"True Positive Rate: \", tpr)\n",
    "print(\"Balanced Accuracy: \", balanced_accuracy)\n",
    "print(\"F1 Score: \", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados: {'logistic_regression__C': 10, 'logistic_regression__solver': 'liblinear'}\n",
      "Accuracy: 0.8152866242038217\n",
      "Recall: 0.44366197183098594\n",
      "True Negative Rate: 0.9447852760736196\n",
      "True Positive Rate: 0.44366197183098594\n",
      "Balanced Accuracy: 0.6942236239523027\n",
      "F1 Score: 0.7983372420176964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Inicializar el modelo de regresión logística\n",
    "logistic_regression = LogisticRegression(random_state=100472097)\n",
    "\n",
    "# Definir el pipeline con el escalador y el modelo\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('logistic_regression', logistic_regression)])\n",
    "\n",
    "# Definir los parámetros para la búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'logistic_regression__C': [0.1, 1, 10],\n",
    "    'logistic_regression__solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "}\n",
    "\n",
    "# Inicializar GridSearchCV\n",
    "logistic_regression_grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajustar el modelo utilizando los datos de entrenamiento\n",
    "logistic_regression_grid_search.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred = logistic_regression_grid_search.predict(x_test_scaled)\n",
    "\n",
    "# Calcular métricas de rendimiento\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "tnr = recall_score(y_test, y_pred, pos_label=0)\n",
    "tpr = recall_score(y_test, y_pred, pos_label=1)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "f1_score_value = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Mejores hiperparámetros encontrados:\", logistic_regression_grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"True Negative Rate:\", tnr)\n",
    "print(\"True Positive Rate:\", tpr)\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy)\n",
    "print(\"F1 Score:\", f1_score_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Matriz de confusión en RL***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión es una herramienta útil para comprender el rendimiento del modelo en la clasificación de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class Pred 0  Class Pred 1\n",
      "Real 0            770            45\n",
      "Real 1            158           126\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index = [\"Real 0\", \"Real 1\"], columns = [\" Class Pred 0\", \"Class Pred 1\"])\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta matriz de confusión:\n",
    "\n",
    "Para la clase verdadera \"0\" (Real 0), el modelo predijo correctamente 770 instancias como \"0\" y erróneamente clasificó 45 instancias como \"1\".\n",
    "Para la clase verdadera \"1\" (Real 1), el modelo predijo correctamente 158 instancias como \"1\" y erróneamente clasificó 129 instancias como \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MEJOR MODELO DE CLASIFICACIÓN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque ya contasemos con los resultados obtenidos por el propio código decidimos tambien hacer los calculos a mano a partir de lo obtenido en las matrices de confusión. Entonces:\n",
    "\n",
    "Para determinar cuál modelo es el mejor, podemos evaluar diferentes métricas de rendimiento, como la precisión, la sensibilidad (recall), la especificidad (True Negative/Possitive Rate), la precisión equilibrada (balanced accuracy) y la puntuación F1.\n",
    "\n",
    "1. **Matriz de Confusión REGRESIÓN LOGISTICA:**\n",
    "   - Precisión: (770 + 158) / (770 + 45 + 129 + 158) = 0.862\n",
    "   - Sensibilidad para la clase 0: 770 / (770 + 45) = 0.945\n",
    "   - Sensibilidad para la clase 1: 158 / (158 + 129) = 0.550\n",
    "   - True Negative Rate: 770 / (770 + 45) = 0.945\n",
    "   - True Positive Rate: 158 / (158 + 129) = 0.550\n",
    "   - Precisión equilibrada: (0.945 + 0.550) / 2 = 0.748\n",
    "   - Puntuación F1: (2 * 0.945 * 0.550) / (0.945 + 0.550) = 0.689\n",
    "\n",
    "2. **Matriz de Confusión ÁRBOLES DE CLASIFICACIÓN:**\n",
    "   - Precisión: (737 + 193) / (737 + 78 + 91 + 193) = 0.840\n",
    "   - Sensibilidad para la clase 0: 737 / (737 + 78) = 0.904\n",
    "   - Sensibilidad para la clase 1: 193 / (193 + 91) = 0.679\n",
    "   - True Negative Rate: 737 / (737 + 78) = 0.904\n",
    "   - True Positive Rate: 193 / (193 + 91) = 0.679\n",
    "   - Precisión equilibrada: (0.904 + 0.679) / 2 = 0.791\n",
    "   - Puntuación F1: (2 * 0.904 * 0.679) / (0.904 + 0.679) = 0.776\n",
    "\n",
    "3. **Matriz de Confusión KNN:**\n",
    "   - Precisión: (778 + 170) / (778 + 37 + 114 + 170) = 0.864\n",
    "   - Sensibilidad para la clase 0: 778 / (778 + 37) = 0.954\n",
    "   - Sensibilidad para la clase 1: 170 / (170 + 114) = 0.598\n",
    "   - True Negative Rate: 778 / (778 + 37) = 0.954\n",
    "   - True Positive Rate: 170 / (170 + 114) = 0.598\n",
    "   - Precisión equilibrada: (0.954 + 0.598) / 2 = 0.776\n",
    "   - Puntuación F1: (2 * 0.954 * 0.598) / (0.954 + 0.598) = 0.737\n",
    "\n",
    "4. **Matriz de Confusión SVM:**\n",
    "   - Precisión: (700 + 231) / (700 + 115 + 53 + 231) = 0.820\n",
    "   - Sensibilidad para la clase 0: 700 / (700 + 115) = 0.859\n",
    "   - Sensibilidad para la clase 1: 231 / (231 + 53) = 0.813\n",
    "   - True Negative Rate: 700 / (700 + 115) = 0.859\n",
    "   - True Positive Rate: 231 / (231 + 53) = 0.813\n",
    "   - Precisión equilibrada: (0.859 + 0.813) / 2 = 0.836\n",
    "   - Puntuación F1: (2 * 0.859 * 0.813) / (0.859 + 0.813) = 0.835\n",
    "\n",
    "Basado en estas métricas:\n",
    "\n",
    "- La **Matriz de Confusión KNN** tiene la mayor precisión equilibrada y una puntuación F1 más alta, lo que indica un mejor rendimiento general del modelo.\n",
    "- La **Matriz de Confusión SVM** también tiene un rendimiento sólido en términos de precisión equilibrada y puntuación F1, siendo una buena opción también.\n",
    "- La **Matriz de Confusión REGRESIÓN LOGÍSTICA** tiene la menor sensibilidad para la clase 1 y una puntuación F1 más baja, lo que indica que no clasifica tan bien la clase 1 como los otros modelos.\n",
    "\n",
    "Por lo tanto, el Mejor Modelo sería el correspondiente a **la Matriz de Confusión KNN**, aunque tiene un True Positive Rate ligeramente más bajo que **la Matriz de Confusión SVM**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLegamos a la misma conclusión a partir de los datos obtenidos con el código:\n",
    "\n",
    "Entonces para determinar el mejor modelo, necesitamos considerar todas las métricas de rendimiento proporcionadas para cada modelo (KNN, árboles de clasificación y regresión logística) tanto con ajustes como sin ajustes de hiperparámetros. Sin embargo, para simplificar, podemos usar una métrica compuesta, como el F1 Score ponderado, que tiene en cuenta la precisión y el recall de cada clase.\n",
    "\n",
    "**SVM:**\n",
    "- Sin ajuste de hiperparámetros: F1 Score ponderado = 0.863\n",
    "- Con ajuste de hiperparámetros: F1 Score ponderado = 0.852\n",
    "\n",
    "**KNN:**\n",
    "- Sin ajustes de hiperparámetros: F1 Score ponderado = 0.664\n",
    "- Con ajustes de hiperparámetros: F1 Score ponderado = 0.854\n",
    "\n",
    "**Árboles de clasificación:**\n",
    "- Sin ajustes de hiperparámetros: F1 Score ponderado = 0.811\n",
    "- Con ajustes de hiperparámetros: F1 Score ponderado = 0.845\n",
    "\n",
    "**Regresión logística:**\n",
    "- Sin ajustes de hiperparámetros: F1 Score ponderado = 0.800\n",
    "- Con ajustes de hiperparámetros: F1 Score ponderado = 0.798\n",
    "\n",
    "El modelo SVM sin ajuste de hiperparámetros supera ligeramente a los otros modelos en términos de F1 Score ponderado, pero el modelo KNN con hiperparámetros ajustados sigue siendo el mejor modelo con un F1 Score ponderado de 0.854. Sin embargo, el modelo SVM con ajuste de hiperparámetros también muestra un rendimiento competitivo con un F1 Score ponderado de 0.852. Dependiendo de otros factores como el tiempo de entrenamiento y la interpretación del modelo, cualquiera de estos modelos podría considerarse como una opción viable.\n",
    "\n",
    "Sin embargo nosotras tras realizar los calculos también a mano decimos quedarnos con el modelo KNN con hiperparámetros ajustados parece ser el mejor modelo para este conjunto de datos. Aunque volvemos a repetir, queda muy proximo a la SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. IMPLICACIONES DE CHATGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el desarrollo de la práctica, nos vimos en la necesidad de recurrir a ChatGPT debido a la falta de conocimientos sólidos sobre el desarrollo del código y los objetivos específicos que estábamos tratando de alcanzar. Esta herramienta desempeñó un papel importante en varias áreas clave:\n",
    "\n",
    "1. **Contextualización y comprensión de comandos**: ChatGPT nos ayudó a situarnos en el contexto de la práctica al proporcionarnos explicaciones claras sobre diversos comandos utilizados para la inserción y eliminación de datos en el archivo. Esta comprensión fue esencial para llevar a cabo las tareas de manera efectiva y eficiente.\n",
    "\n",
    "2. **Limitaciones en la ayuda teórica**: Aunque también buscamos orientación teórica, encontramos ciertas limitaciones en la capacidad de ChatGPT para proporcionar respuestas precisas y relevantes. En algunas ocasiones, las respuestas se desviaban del tema central o no abordaban completamente nuestras preguntas, lo que dificultaba el proceso de aprendizaje. Sin embargo, cuando sucedía esto podiamos recurrir a las diapositivas que nos ayudan un poco más.\n",
    "\n",
    "3. **Interpretación de resultados**: En momentos en que los resultados eran ambiguos o similares entre sí, ChatGPT fue útil para sugerir otras métricas o enfoques que podríamos considerar para tomar decisiones informadas. Su capacidad para ofrecer diferentes perspectivas nos permitió evaluar exhaustivamente los resultados y seleccionar la mejor opción.\n",
    "\n",
    "4. **Contribución al proceso de codificación**: Si bien la participación de ChatGPT en el desarrollo del código no fue predominante, aproximadamente un 20% del proceso estuvo influenciado por sus sugerencias y explicaciones. Aunque comenzamos con el código proporcionado en clase, a menudo encontramos dificultades para comprenderlo completamente y adaptarlo a nuestras necesidades específicas. En estas situaciones, la claridad y orientación proporcionadas por ChatGPT fueron invaluables para superar los desafíos técnicos.\n",
    "\n",
    "5. **Gestión de errores**: Una parte significativa de nuestra resolución de problemas estuvo vinculada a la ayuda de ChatGPT. Estimamos que alrededor del 40% de los errores detectados fueron resueltos gracias a sus explicaciones y sugerencias. En casos donde los errores eran complejos o no podíamos identificar la causa raíz, la capacidad de ChatGPT para proporcionar una orientación detallada fue crucial para encontrar soluciones efectivas.\n",
    "\n",
    "En resumen, la utilización de ChatGPT en el desarrollo de la práctica fue fundamental para superar las limitaciones de nuestro conocimiento y abordar los desafíos técnicos de manera efectiva. Su capacidad para proporcionar orientación contextual, interpretar resultados y ayudar en la resolución de problemas contribuyó significativamente a nuestro proceso de aprendizaje y desarrollo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
